services:
  namenode:
    image: harisekhon/hadoop:latest
    container_name: namenode
    hostname: namenode
    ports:
      - "9870:9870"
      - "9000:9000"
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    volumes:
      - namenode:/hadoop/dfs/name
      - ./data:/data
      - ./scripts:/scripts
      - ./output:/output

  datanode:
    image: harisekhon/hadoop:latest
    container_name: datanode
    hostname: datanode
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=1
      - SERVICE_PRECONDITION=namenode:9000
    volumes:
      - datanode:/hadoop/dfs/data
      - ./data:/data
    depends_on:
      - namenode

  secondarynamenode:
    image: harisekhon/hadoop:latest
    container_name: secondarynamenode
    hostname: secondarynamenode
    command: ["hdfs", "secondarynamenode"]
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SERVICE_PRECONDITION=namenode:9000
    ports:
      - "9868:9868"
    volumes:
      - secondarynamenode:/hadoop/dfs/secondary
    depends_on:
      - namenode

  python-ml:
    image: python:3.10-slim
    container_name: python-ml
    volumes:
      - ./output:/output
      - ./scripts:/scripts
    working_dir: /scripts
    command: tail -f /dev/null

volumes:
  namenode:
  datanode:
  secondarynamenode:
